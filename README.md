# ðŸ“¦ Amazon Reviews Sentiment Classification â€“ NLP Final Project
This is the final Project for CSCI 3832 for Adam Wuth, Benjamin Kohav, Noah Vilas, Aiden Devine, Evan Zachary

## Overview
This project uses different models to predict star ratings (1 to 5) from Amazon product reviews written in 2023. We compare different model architectures (e.g., N-gram models vs. DistilBERT) to evaluate how well they classify sentiment in real-world amazon review data.



## Final Results(all tested on the same dataset created in the make_dataset notebook)
1. Bigram model accuracy:22%
2. RNN model Accuracy:20.1%
3. 
## Different Parts of the code
In this repository, you will find 6 notebooks:
1. Make_Dataset.ipynb
2. DistillBERT.ipynb
3. placeholder
4. placeholder
5. placeholder
6. placeholder
<br/>
Each notebook holds a different model. In order to recreate our results, you only need to follow the instructions and run the code in each notebook.
## Dataset
Years Filtered: Only 2023 reviews<br/>
Source Domains: 34 Amazon product categories<br/>
Preprocessing:<br/>
Filter by timestamp, review type and category<br/>
Map rating to label classes 0â€“4<br/>
Split:80% training, 20% validation<br/>
**To recreate the project, use the make dataset notebook**
## Link to Github and GoogleDrive
1. Link to github used in development: https://github.com/Adam-Wuth/NLP-project.git
2. Link to final github: https://github.com/Adam-Wuth/Amazon_Reviews_NLP.git
3. Link to Google Drive containing additional resources:

## Authorship, attribution, and acknowledgements
**Dataset setup and filtering:**<br/>
Adam Wuth, *Lead*<br/>
<br/>
**DistillBERT Code:**<br/>
Adam Wuth, *Lead*<br/>
<br/>
**RNN Code:**<br/>
Aiden Devine, *Lead*
Adam Wuth, *Contributer*<br/>
<br/>
**Bigram Model Code:**<br/>
Benjamin Kohav, *Lead*<br/>
<br/>
